# Completed Stations
CompleteScenL <- length(c()) #Fill in with completed StaTDL stations
# Staions Remaining
StaTDL<-c(1,6,5,2:4,7:9,24:28,59:53,84:77,92,91,
90:85,100:97,96,95:93,107:105,110,119,117,115,124,122,128,127)
### Cutting B stations for time
STA.0516 <- c(157:159,166,168,170,172,174,176,178:180)
STA.0520 <- c(167:177) # All Shelikof Stations Cut
#B_Drop_Vec <- c(STA.0516,STA.0517)
#Drop Stations by subset using updated above vector, keep drops by date
#WGOAdata <- WGOAdata %>% subset(!(Station %in% STA.0516))
# Save CSV of above for Day to Day
#write.csv(WGOAdata, here("Data","DY23-07_Day2Day.csv"))
# Reverse Order Stations for Reference (DO NOT DELETE)
#
#            c(1:9,24:28,59:53,84:77, 92:85, 100:93, 107:101,113:108,119:114,
#           125:120, 131:126, 136:132,141:137, 142:142,152:148, 156:153, 159:157,165:160,
#           166:179,180,213:208,216:220,228:225,234:238,271)
ScenName <- "Stations Completed"
Scenario<-StaTDL # Always Change to Updated Stations Remaining
FinalSta<-data.frame("Station"=Scenario,"Stn_Order"= (CompleteScenL+1):(CompleteScenL+length(Scenario)))
# 1. Station Selection Through Scenario (above)
Sta <- WGOAdata %>% left_join(.,FinalSta) %>%
filter(Station %in% FinalSta$Station) %>%
arrange(Stn_Order)
# 2. Choose Departure Date
#DH_SIP <- ymd_hm("2023-05-15 12:00")
#depart <- DH_SIP + dhours(9) # pre-survey calculations, takes ~8 hours to get to STA 1 from DH
# Use below during survey
depart <- lubridate::now(tzone = "America/Anchorage") + dhours(16.5) # Alaska time, for at sea calculations
# 3. Create data.frame that mirrors "Final Station Runtime.xlsx"=
SRTdata <- Sta %>%
mutate(Bongo_hrs = ifelse(Gear.Sampled == "BONGO", 0.33,0)) %>% # BONGO at all stations
mutate(BON_CTD_hrs = ifelse(Gear.Sampled == "BONGO,CTD",0.83,0)) %>%
mutate(BON_CalVET_hrs = ifelse(Gear.Sampled == "BONGO,CALVET", 0.66,0)) %>%
mutate(BON_Cal_CTD_hrs = ifelse(Gear.Sampled == "BONGO,CALVET,CTD",1.16,0)) %>%
#<<<<<<< Updated upstream
mutate(Station_Time = lubridate::dhours(rowSums(across(c(Bongo_hrs,BON_CTD_hrs,BON_CalVET_hrs,BON_Cal_CTD_hrs))))) %>%
mutate(Ship_Speed = 11) %>%  # Ship speed is Variable
mutate(lat_rad = LAT*pi/180) %>% mutate(long_rad = LON*pi/180) %>%
mutate(long_dif = long_rad - shift(long_rad)) %>%
#>>>>>>> Stashed changes
mutate(Dist_NM = ifelse(Station == 0,0,0) ) %>%
mutate(Dist_NM = distGeo(cbind(LON,LAT),cbind(shift(LON),shift(LAT)))/(1000*1.852)) %>%
# distGEO does what code below does in base r
#  mutate(Dist_NM = acos((sin(lag(lat_rad))*sin(lat_rad))+(cos(lag(lat_rad))*cos(lat_rad)*cos(long_dif)))/(pi/180)*60) %>%
mutate(Steam_T = Dist_NM/Ship_Speed) %>%
mutate(Steam_T = lubridate::dhours(Steam_T))
# Write .csv of new Station Order for Oscar Dyson crew
ODsta <- SRTdata %>% select(Grid.ID,LAT,LON,Gear.Sampled,Stn_Order)
#write.csv(ODsta, here("Data","For Dyson","DY23-07 Survey Station Order.csv"), row.names = FALSE) #Error if file open
# 4. rearrange data to calculate time to travel to and complete station operations
shipslog <- SRTdata %>% select(Station, Grid.ID, Station_Time, Steam_T, Stn_Order) %>% # SRTdata will be replaced by filtered stations above
unite("Station",Station:Grid.ID, sep = "_", remove = FALSE) %>%
select(Station,Steam_T,Station_Time,Stn_Order) %>%
gather(key="Ops", Time_Dur, -Station,-Stn_Order) %>% arrange(Station) %>%
separate(Station, c("Station","Grid.ID"), sep = "_") %>%
transform(Station = as.numeric(Station)) %>% arrange(Stn_Order)
shipslog <- na.omit(shipslog)
# 5. Create a table of Station Completion Times
ShipsLog <- shipslog %>% group_by(Stn_Order, Station, Grid.ID) %>%
reframe(Time_Dur = lubridate::dseconds(sum(Time_Dur)))  %>%
mutate(Sta_Time =  depart) %>% mutate(cTime_Dur = cumsum(Time_Dur)) %>%
mutate(Sta_Time = cTime_Dur + Sta_Time) %>% select(Stn_Order, Grid.ID,Sta_Time) %>%
rename("Station"="Stn_Order","Grid Station"="Grid.ID","Est.Station Time"="Sta_Time")
#6. Create a table to link Gear.Sampled for daily stations in ShipsLog to know Operations at each station
Sta_GearSamp <- SRTdata %>% select(Station,Grid.ID,LAT,LON,Gear.Sampled) %>%
filter(Station %in% FinalSta$Station) %>% select(Grid.ID,LAT,LON,Gear.Sampled) %>%
rename("Grid Station"="Grid.ID")
ShipsLog <- left_join(ShipsLog,Sta_GearSamp, by = "Grid Station") %>%
#select(Station,`Grid Station`,Gear.Sampled)
select(Station,`Grid Station`,LAT,LON,Gear.Sampled,`Est.Station Time`)
View(ShipsLog)
here()
write.csv(ShipsLog,here("Docs","DY23-07_Spr_Larval_Completed_Sta.csv"))
View(FinalSta)
#Install Packages
ipak <- function(pkg){
new.pkg <- pkg[!(pkg %in% installed.packages()[, "Package"])]
if (length(new.pkg))
install.packages(new.pkg, dependencies = TRUE)
sapply(pkg, require, character.only = TRUE)
}
packages <- c("tidyr",  "dplyr","lubridate","hms", "ggplot2", "ggmap", "lattice", "stringr", "data.table",
"tibble","readxl", "sf","maps", "mapdata", "mapplots", "mapview", "marmap", "Cairo", "ncdf4",
"oce", "here","reshape2", "viridis", "export", "rnaturalearth", "kableExtra",
"rnaturalearthdata", "forcats","sf", "geosphere")
ipak(packages)
# Create Base Layer Maps will all numbered stations labeled, with a more focused region (not whole WGOA)
world <- ne_countries(scale = "medium", returnclass = "sf")
class(world)
# Load Station Data Table from DY19-05
#WGOAdata <- read.csv(here("Data","WGOA station_list_dougherty_2019_ProjInstrutions.csv"))
WGOAdata <- read.csv(here("Data","DY23-07_A&B_priority FINAL LIST.csv"))
### Create Station & Runtime Dataset ############
###All Stations: based on "Station Column" of "WGOA station_list_dougherty_2019_ProjInstrutions.csv", currently
# in "Data"
AllSta<- c(0, 1:9,28:24,38:44,59:53,68:179,180,213:208,216:220,228:225,234:238,271)
# Log of Removed Stations before Survey
# (5/11/23): B 38:44,68:76
#Stations Left to Sample
# Completed Stations
CompleteScenL <- length(c()) #Fill in with completed StaTDL stations
# Staions Remaining
StaTDL<-c(1,6,5,2:4,7:9,24:28,59:53,84:77,92,91,
90:85,100:97,96,95:93,107:105,110,119,117,115,124,122,128,127)
### Cutting B stations for time
STA.0516 <- c(157:159,166,168,170,172,174,176,178:180)
STA.0520 <- c(167:177) # All Shelikof Stations Cut
#B_Drop_Vec <- c(STA.0516,STA.0517)
#Drop Stations by subset using updated above vector, keep drops by date
#WGOAdata <- WGOAdata %>% subset(!(Station %in% STA.0516))
# Save CSV of above for Day to Day
#write.csv(WGOAdata, here("Data","DY23-07_Day2Day.csv"))
# Reverse Order Stations for Reference (DO NOT DELETE)
#
#            c(1:9,24:28,59:53,84:77, 92:85, 100:93, 107:101,113:108,119:114,
#           125:120, 131:126, 136:132,141:137, 142:142,152:148, 156:153, 159:157,165:160,
#           166:179,180,213:208,216:220,228:225,234:238,271)
ScenName <- "Stations Completed"
Scenario<-StaTDL # Always Change to Updated Stations Remaining
FinalSta<-data.frame("Station"=Scenario,"Stn_Order"= (CompleteScenL+1):(CompleteScenL+length(Scenario)))
# 1. Station Selection Through Scenario (above)
Sta <- WGOAdata %>% left_join(.,FinalSta) %>%
filter(Station %in% FinalSta$Station) %>%
arrange(Stn_Order)
# 2. Choose Departure Date
#DH_SIP <- ymd_hm("2023-05-15 12:00")
#depart <- DH_SIP + dhours(9) # pre-survey calculations, takes ~8 hours to get to STA 1 from DH
# Use below during survey
depart <- lubridate::now(tzone = "America/Anchorage") + dhours(16.5) # Alaska time, for at sea calculations
# 3. Create data.frame that mirrors "Final Station Runtime.xlsx"=
SRTdata <- Sta %>%
mutate(Bongo_hrs = ifelse(Gear.Sampled == "BONGO", 0.33,0)) %>% # BONGO at all stations
mutate(BON_CTD_hrs = ifelse(Gear.Sampled == "BONGO,CTD",0.83,0)) %>%
mutate(BON_CalVET_hrs = ifelse(Gear.Sampled == "BONGO,CALVET", 0.66,0)) %>%
mutate(BON_Cal_CTD_hrs = ifelse(Gear.Sampled == "BONGO,CALVET,CTD",1.16,0)) %>%
#<<<<<<< Updated upstream
mutate(Station_Time = lubridate::dhours(rowSums(across(c(Bongo_hrs,BON_CTD_hrs,BON_CalVET_hrs,BON_Cal_CTD_hrs))))) %>%
mutate(Ship_Speed = 11) %>%  # Ship speed is Variable
mutate(lat_rad = LAT*pi/180) %>% mutate(long_rad = LON*pi/180) %>%
mutate(long_dif = long_rad - shift(long_rad)) %>%
#>>>>>>> Stashed changes
mutate(Dist_NM = ifelse(Station == 0,0,0) ) %>%
mutate(Dist_NM = distGeo(cbind(LON,LAT),cbind(shift(LON),shift(LAT)))/(1000*1.852)) %>%
# distGEO does what code below does in base r
#  mutate(Dist_NM = acos((sin(lag(lat_rad))*sin(lat_rad))+(cos(lag(lat_rad))*cos(lat_rad)*cos(long_dif)))/(pi/180)*60) %>%
mutate(Steam_T = Dist_NM/Ship_Speed) %>%
mutate(Steam_T = lubridate::dhours(Steam_T))
# Write .csv of new Station Order for Oscar Dyson crew
ODsta <- SRTdata %>% select(Grid.ID,LAT,LON,Gear.Sampled,Stn_Order)
#write.csv(ODsta, here("Data","For Dyson","DY23-07 Survey Station Order.csv"), row.names = FALSE) #Error if file open
# 4. rearrange data to calculate time to travel to and complete station operations
shipslog <- SRTdata %>% select(Station, Grid.ID, Station_Time, Steam_T, Stn_Order) %>% # SRTdata will be replaced by filtered stations above
unite("Station",Station:Grid.ID, sep = "_", remove = FALSE) %>%
select(Station,Steam_T,Station_Time,Stn_Order) %>%
gather(key="Ops", Time_Dur, -Station,-Stn_Order) %>% arrange(Station) %>%
separate(Station, c("Station","Grid.ID"), sep = "_") %>%
transform(Station = as.numeric(Station)) %>% arrange(Stn_Order)
shipslog <- na.omit(shipslog)
# 5. Create a table of Station Completion Times
ShipsLog <- shipslog %>% group_by(Stn_Order, Station, Grid.ID) %>%
reframe(Time_Dur = lubridate::dseconds(sum(Time_Dur)))  %>%
mutate(Sta_Time =  depart) %>% mutate(cTime_Dur = cumsum(Time_Dur)) %>%
mutate(Sta_Time = cTime_Dur + Sta_Time) %>% select(Stn_Order, Grid.ID,Sta_Time) %>%
rename("Station"="Stn_Order","Grid Station"="Grid.ID","Est.Station Time"="Sta_Time")
#6. Create a table to link Gear.Sampled for daily stations in ShipsLog to know Operations at each station
Sta_GearSamp <- SRTdata %>% select(Station,Grid.ID,LAT,LON,Gear.Sampled) %>%
filter(Station %in% FinalSta$Station) %>% select(Grid.ID,LAT,LON,Gear.Sampled) %>%
rename("Grid Station"="Grid.ID")
ShipsLog <- left_join(ShipsLog,Sta_GearSamp, by = "Grid Station") %>%
select(Station,`Grid Station`,Gear.Sampled)
#select(Station,`Grid Station`,LAT,LON,Gear.Sampled,`Est.Station Time`)
#write.csv(ShipsLog,here("Docs","DY23-07_Spr_Larval_Completed_Sta.csv"))
# Output Station Table, include: Ships Log
kbl(ShipsLog, caption = "Next Stations", booktabs = T) %>%
kableExtra::kable_styling(bootstrap_options = "bordered", latex_options = c("striped", "HOLD_position"))
View(ShipsLog)
View(SRTdata)
View(SRTdata)
write.csv(ODsta, here("Data","For Dyson","DY23-07 Survey Station Order.csv"), row.names = FALSE)
ODsta <- SRTdata %>% select(Grid.ID,LAT,LON,Gear.Sampled,Stn_Order,Dist_NM)
write.csv(ODsta, here("Data","For Dyson","DY23-07 Survey Station Order.csv"), row.names = FALSE) #E
here()
View(ODsta)
library(RODBC)
library(tidyverse)
library(readr)
library(here)
{user <- readline("Input Username: " )
pswd <- readline("Input Password: " )}
AFSC_Connect <- odbcConnect("AFSC", uid=user,  pwd=pswd)
sqlQuery(AFSC_Connect,"DROP TABLE SPECIMEN_MAIN_GEOM;")
sqlQuery(AFSC_Connect,"CREATE TABLE SPECIMEN_MAIN_GEOM AS SELECT * FROM ECODAAT.SPECIMEN_MAIN_GEOM;")
zoopdata <- sqlQuery(AFSC_Connect, "SELECT
CRUISE, DAY, DIS_PERVOLM2, DIS_PERVOLM3, EST_NUM_PERM2, EST_NUM_PERM3, FOCI_ID, FOCI_SAMPLE_ID, GEAR_NAME,
GEOGRAPHIC_AREA,GRID_ID, GMT_DATE_TIME_TXT, HAUL_ID, HAUL_NAME, HAUL_PERFORMANCE, LAT, LON, BOTTOM_DEPTH,MAX_GEAR_DEPTH, MESH,
MIN_GEAR_DEPTH, MONTH, NET, SAMPLE_DEPTH, SEX, SEX_NAME, SIZE_NAME, SPECIMEN_FORM, STAGE, STAGE_NAME, STATION_NAME,
TAXON_NAME, TAXON_SIZE, VOLUME_FILTERED, YEAR, ZOOP_COPEPOD_NAUPLII, ZOOP_EUPHAUSIID_EGG
FROM SPECIMEN_MAIN_GEOM WHERE ORIG_DB LIKE 'BOB';", stringsAsFactors=FALSE)
write.csv(zoopdata, here("Data", "2023_10_12-All_Zooplankton.csv"))
sqlQuery(AFSC_Connect,"DROP TABLE SPECIMEN_MAIN_GEOM;")
sqlQuery(AFSC_Connect,"CREATE TABLE SPECIMEN_MAIN_GEOM AS SELECT * FROM ECODAAT.SPECIMEN_MAIN_GEOM;")
zoopdata <- sqlQuery(AFSC_Connect, "SELECT
CRUISE, DAY, DIS_PERVOLM2, DIS_PERVOLM3, EST_NUM_PERM2, EST_NUM_PERM3, FOCI_ID, FOCI_SAMPLE_ID, GEAR_NAME,
GEOGRAPHIC_AREA, GMT_DATE_TIME_TXT, HAUL_ID, HAUL_NAME, HAUL_PERFORMANCE, LAT, LON, MAX_GEAR_DEPTH, MESH,
MIN_GEAR_DEPTH, MONTH, NET, SAMPLE_DEPTH, SEX, SEX_NAME, SIZE_NAME, SPECIMEN_FORM, STAGE, STAGE_NAME, STATION_NAME,
TAXON_NAME, TAXON_SIZE, VOLUME_FILTERED, YEAR, ZOOP_COPEPOD_NAUPLII, ZOOP_EUPHAUSIID_EGG
FROM SPECIMEN_MAIN_GEOM WHERE ORIG_DB LIKE 'BOB';", stringsAsFactors=FALSE)
write.csv(zoopdata, here("Data", "2023_10_12-All_Zooplankton.csv"))
odbcClose(AFSC_Connect)
AFSC_Connect <- odbcConnect("AFSC", uid=user,  pwd=pswd)
sqlQuery(AFSC_Connect,"DROP TABLE SPECIMEN_MAIN_GEOM;")
sqlQuery(AFSC_Connect,"CREATE TABLE SPECIMEN_MAIN_GEOM AS SELECT * FROM ECODAAT.SPECIMEN_MAIN_GEOM;")
zoopdata <- sqlQuery(AFSC_Connect, "SELECT
CRUISE, DAY, DIS_PERVOLM2, DIS_PERVOLM3, EST_NUM_PERM2, EST_NUM_PERM3, FOCI_ID, FOCI_SAMPLE_ID, GEAR_NAME,
GEOGRAPHIC_AREA, GMT_DATE_TIME_TXT, HAUL_ID, HAUL_NAME, HAUL_PERFORMANCE, LAT, LON, MAX_GEAR_DEPTH, MESH,
MIN_GEAR_DEPTH, MONTH, NET, SAMPLE_DEPTH, SEX, SEX_NAME, SIZE_NAME, SPECIMEN_FORM, STAGE, STAGE_NAME, STATION_NAME,
TAXON_NAME, TAXON_SIZE, VOLUME_FILTERED, YEAR, ZOOP_COPEPOD_NAUPLII, ZOOP_EUPHAUSIID_EGG
FROM SPECIMEN_MAIN_GEOM WHERE ORIG_DB LIKE 'BOB';", stringsAsFactors=FALSE)
write.csv(zoopdata, here("Data", "2023_10_12-All_Zooplankton.csv"))
odbcClose(AFSC_Connect)
here()
AFSC_Connect <- odbcConnect("AFSC", uid=user,  pwd=pswd)
sqlQuery(AFSC_Connect,"DROP TABLE SPECIMEN_MAIN_GEOM;")
sqlQuery(AFSC_Connect,"CREATE TABLE SPECIMEN_MAIN_GEOM AS SELECT * FROM ECODAAT.SPECIMEN_MAIN_GEOM;")
zoopdata <- sqlQuery(AFSC_Connect, "SELECT
BOTTOM_DEPTH ,CRUISE, DAY, DIS_PERVOLM2, DIS_PERVOLM3, EST_NUM_PERM2, EST_NUM_PERM3, FOCI_ID,FOCI_GRID, FOCI_SAMPLE_ID, GEAR_NAME,
GEOGRAPHIC_AREA, GMT_DATE_TIME_TXT, HAUL_ID, HAUL_NAME, HAUL_PERFORMANCE, LAT, LON, MAX_GEAR_DEPTH, MESH,
MIN_GEAR_DEPTH, MONTH, NET, SAMPLE_DEPTH, SEX, SEX_NAME, SIZE_NAME, SPECIMEN_FORM, STAGE, STAGE_NAME, STATION_NAME,
TAXON_NAME, TAXON_SIZE, VOLUME_FILTERED, YEAR, ZOOP_COPEPOD_NAUPLII, ZOOP_EUPHAUSIID_EGG
FROM SPECIMEN_MAIN_GEOM WHERE ORIG_DB LIKE 'BOB';", stringsAsFactors=FALSE)
write.csv(zoopdata, here("Data", "2023_10_12-All_Zooplankton.csv"))
odbcClose(AFSC_Connect)
#Install Packages
ipak <- function(pkg){
new.pkg <- pkg[!(pkg %in% installed.packages()[, "Package"])]
if (length(new.pkg))
install.packages(new.pkg, dependencies = TRUE)
sapply(pkg, require, character.only = TRUE)
}
packages <- c("tidyr",  "dplyr","lubridate","hms", "ggplot2", "ggmap", "lattice", "stringr", "data.table",
"tibble","readxl", "sf","maps", "mapdata", "mapplots", "mapview", "marmap", "Cairo", "ncdf4",
"oce", "here","reshape2", "viridis", "export", "rnaturalearth", "kableExtra",
"rnaturalearthdata", "forcats","sf", "geosphere")
ipak(packages)
# Create Base Layer Maps will all numbered stations labeled, with a more focused region (not whole WGOA)
world <- ne_countries(scale = "medium", returnclass = "sf")
class(world)
#Install Packages
ipak <- function(pkg){
new.pkg <- pkg[!(pkg %in% installed.packages()[, "Package"])]
if (length(new.pkg))
install.packages(new.pkg, dependencies = TRUE)
sapply(pkg, require, character.only = TRUE)
}
packages <- c("tidyr",  "dplyr","lubridate","hms", "ggplot2", "ggmap", "lattice", "stringr", "data.table",
"tibble","readxl", "sf","maps", "mapdata", "mapplots", "mapview", "marmap", "Cairo", "ncdf4",
"oce", "here","reshape2", "viridis", "export", "rnaturalearth",
"rnaturalearthdata", "forcats","sf", "geosphere")
ipak(packages)
# Create Base Layer Maps will all numbered stations labeled, with a more focused region (not whole WGOA)
world <- ne_countries(scale = "medium", returnclass = "sf")
class(world)
# Read in "late-larval core" region used for larval time-series, as shapefile:
# convert to Lat/lon projection.
shp.mp <- read_sf(dsn=here("Data","mapping_data","NewLateLarvalPolygon"),layer="Survey_poly")
#shp.mp.LL<-st_transform(shp.mp,CRS("+proj=longlat"))
shp.mp.LL<-st_transform(shp.mp,crs=("+proj=longlat"))
WGOAdata <- read.csv(here("Data","WGOA station_list_dougherty_2019_ProjInstrutions.csv"))
GridStaData <- read.csv(here("Data","2023_10_12-All_Zooplankton.csv"))
# If using "WGOA station_list_dougherty_2019_ProjInstrutions.csv" as WGOAdata, run the following
WGOAdata <- WGOAdata %>% rename("LAT" = "Latitude.N.") %>% rename("LON"="Longitude..W.")
WGOAdata$LON <- WGOAdata$LON*-1
# Count Gear.Sampled
table(WGOAdata$Gear.Sampled)
# get bathymetry data
b = getNOAA.bathy(lon1 = -166, lon2 = -140, lat1 = 52, lat2 = 62,
resolution = 15)
## Querying NOAA database ...
## This may take seconds to minutes, depending on grid size
## Building bathy matrix ...
# convert bathymetry to data frame
bf = fortify.bathy(b)
# get regional polygons
reg = map_data("world2Hires")
reg = subset(reg, region %in% c('USSR', 'USA'))
# convert lat longs
reg$long = (360 - reg$long)*-1
# set map limits, whole region
lons = c(-167, -149) #-140 = large map
lats = c(53, 60.25) # 52 = large map
######################################
# make plot
GOARegion_Map_New <- ggplot()+
# add 50m contour
geom_contour(data = bf, aes(x=x, y=y, z=z),breaks=c(-50),linewidth=c(0.5),colour="light grey")+
# add 100m contour
geom_contour(data = bf, aes(x=x, y=y, z=z),breaks=c(-100),linewidth=c(0.5),colour="darkgrey")+
# add 200m contour
geom_contour(data = bf, aes(x=x, y=y, z=z),breaks=c(-200),linewidth=c(0.5),colour="black")+
# add late larval "core" polygon
# geom_sf(data = shp.mp.LL, color="green", fill=NA, linewidth = 1.5) +
# add coastline
geom_sf(data = world)+
coord_sf(xlim = lons, ylim = lats, expand = FALSE)+
#Plot WGOA points
geom_point(data = WGOAdata, mapping = aes(Longitude..W., Latitude.N., shape = Gear.Sampled),
size = 1, show.legend = FALSE)+
#Delete "shape..." for just stations
geom_text(data = WGOAdata, mapping = aes(Longitude..W., Latitude.N., label = Station ),
nudge_y = -0.08, size = 2.5)+
#station text size & nudge NOT IN 'aes' configure projection and plot domain coord_map(xlim = lons, ylim = lats)+
# formatting
scale_shape_discrete()+
theme_bw()+
xlab("Longitude")+
ylab("Latitude")+
theme(axis.text.x=element_text(size=10, color = "black"), axis.text.y = element_text(size=10, color = "black"))
#GOARegion_Map_New
#ggsave("SpringLarval_AllSTA_2023_Gear&StationNo.png",path = here("Docs"), height = 8.5, width = 11, units = "in")
glimpse(GridStaData)
unique(GridStaData$GEOGRAPHIC_AREA)
GridStaData <- GridStaData %>% filter(GEOGRAPHIC_AREA = "GOA") %>%
select(CRUISE,GMT_DATE_TIME_TXT,FOCI_GRID,
GEAR_NAME,BOTTOM_DEPTH,LAT,LON,
MAX_GEAR_DEPTH,YEAR)
GridStaData <- GridStaData %>% filter(GEOGRAPHIC_AREA == "GOA") %>%
select(CRUISE,GMT_DATE_TIME_TXT,FOCI_GRID,
GEAR_NAME,BOTTOM_DEPTH,LAT,LON,
MAX_GEAR_DEPTH,YEAR)
write.csv(GridStaData, file = here("Data","2023-10-18 WGOA Grid Sta Depth Data.csv"))
gc()
#Install Packages
ipak <- function(pkg){
new.pkg <- pkg[!(pkg %in% installed.packages()[, "Package"])]
if (length(new.pkg))
install.packages(new.pkg, dependencies = TRUE)
sapply(pkg, require, character.only = TRUE)
}
packages <- c("tidyr",  "dplyr","lubridate","hms", "ggplot2", "ggmap", "lattice", "stringr", "data.table",
"tibble","readxl", "sf","maps", "mapdata", "mapplots", "mapview", "marmap", "Cairo", "ncdf4",
"oce", "here","reshape2", "viridis", "export", "rnaturalearth",
"rnaturalearthdata", "forcats","sf", "geosphere")
ipak(packages)
# Create Base Layer Maps will all numbered stations labeled, with a more focused region (not whole WGOA)
world <- ne_countries(scale = "medium", returnclass = "sf")
class(world)
# Read in "late-larval core" region used for larval time-series, as shapefile:
# convert to Lat/lon projection.
shp.mp <- read_sf(dsn=here("Data","mapping_data","NewLateLarvalPolygon"),layer="Survey_poly")
#shp.mp.LL<-st_transform(shp.mp,CRS("+proj=longlat"))
shp.mp.LL<-st_transform(shp.mp,crs=("+proj=longlat"))
WGOAdata <- read.csv(here("Data","WGOA station_list_dougherty_2019_ProjInstrutions.csv"))
GridStaData <- read.csv(here("Data","2023-10-18 WGOA Grid Sta Depth Data.csv"))
# If using "WGOA station_list_dougherty_2019_ProjInstrutions.csv" as WGOAdata, run the following
WGOAdata <- WGOAdata %>% rename("LAT" = "Latitude.N.") %>% rename("LON"="Longitude..W.")
WGOAdata$LON <- WGOAdata$LON*-1
# Count Gear.Sampled
table(WGOAdata$Gear.Sampled)
# get bathymetry data
b = getNOAA.bathy(lon1 = -166, lon2 = -140, lat1 = 52, lat2 = 62,
resolution = 15)
## Querying NOAA database ...
## This may take seconds to minutes, depending on grid size
## Building bathy matrix ...
# convert bathymetry to data frame
bf = fortify.bathy(b)
# get regional polygons
reg = map_data("world2Hires")
reg = subset(reg, region %in% c('USSR', 'USA'))
# convert lat longs
reg$long = (360 - reg$long)*-1
# set map limits, whole region
lons = c(-167, -149) #-140 = large map
lats = c(53, 60.25) # 52 = large map
######################################
# make plot
GOARegion_Map_New <- ggplot()+
# add 50m contour
geom_contour(data = bf, aes(x=x, y=y, z=z),breaks=c(-50),linewidth=c(0.5),colour="light grey")+
# add 100m contour
geom_contour(data = bf, aes(x=x, y=y, z=z),breaks=c(-100),linewidth=c(0.5),colour="darkgrey")+
# add 200m contour
geom_contour(data = bf, aes(x=x, y=y, z=z),breaks=c(-200),linewidth=c(0.5),colour="black")+
# add late larval "core" polygon
# geom_sf(data = shp.mp.LL, color="green", fill=NA, linewidth = 1.5) +
# add coastline
geom_sf(data = world)+
coord_sf(xlim = lons, ylim = lats, expand = FALSE)+
#Plot WGOA points
geom_point(data = WGOAdata, mapping = aes(Longitude..W., Latitude.N., shape = Gear.Sampled),
size = 1, show.legend = FALSE)+
#Delete "shape..." for just stations
geom_text(data = WGOAdata, mapping = aes(Longitude..W., Latitude.N., label = Station ),
nudge_y = -0.08, size = 2.5)+
#station text size & nudge NOT IN 'aes' configure projection and plot domain coord_map(xlim = lons, ylim = lats)+
# formatting
scale_shape_discrete()+
theme_bw()+
xlab("Longitude")+
ylab("Latitude")+
theme(axis.text.x=element_text(size=10, color = "black"), axis.text.y = element_text(size=10, color = "black"))
#GOARegion_Map_New
#ggsave("SpringLarval_AllSTA_2023_Gear&StationNo.png",path = here("Docs"), height = 8.5, width = 11, units = "in")
unique(GridStaData$YEAR)
count(unique(GridStaData$FOCI_GRID))
unique(GridStaData$FOCI_GRID)
GridMeanZ <- GridStaData %>% group_by(FOCI_GRID) %>% summarise(MeanZ = mean(BOTTOM_DEPTH))
View(GridMeanZ)
### Create Station & Runtime Dataset, mirroring "Final Station Runtime" Spreadsheets
# Filter out Stations
# LLC = "late larval core" from polygon plot above
#LLCvec <- c(0,60:225,271)
AllSTA <- WGOAdata$Station #See line 202 below
#Scen1<-c(0,24:28,44:38,53:59,60:179, 180, 181,201:197,208:213, 216,218,220,228:225,
#         234:238,239, 245:243,249:251,257:255,261:263, 269:267,271)
ScenName <- "All Possible Stations from DY19-05"
Scenario<-AllSTA
FinalSta<-data.frame("Station"=Scenario,"Stn_Order"=1:length(Scenario))
# Station Selection Through Omission (Example Below)
# AllSta <- c(0:271) # All Possible Stations
# OmitSta <- c(0,60:225,271) # Stations to leave out
# FinalSta <- setdiff(AllSta,LLCvec) # All stations left
Sta <- WGOAdata %>% left_join(.,FinalSta) %>%
filter(Station %in% FinalSta$Station) %>%
arrange(Stn_Order)
# 1. Create data.frame that mirrors "Final Station Runtime"
SRTdata <- Sta %>% #rename(LAT = Latitude.N., LON = Longitude..W.) %>%
mutate(Gear.Sampled = replace(Gear.Sampled,Gear.Sampled == "","BONGO")) %>%
mutate(Gear.Sampled = replace(Gear.Sampled,Gear.Sampled == "NEU","BONGO")) %>%
mutate(Gear.Sampled =  replace(Gear.Sampled,Gear.Sampled == "NEU, CTD","BONGO,CTD")) %>%
mutate(Gear.Sampled = replace(Gear.Sampled,Gear.Sampled == "CTD","BONGO,CTD")) %>%
mutate(Gear.Sampled = replace(Gear.Sampled,Gear.Sampled == "CALVET","BONGO,CALVET")) %>%
mutate(Gear.Sampled = replace(Gear.Sampled,Gear.Sampled == "CALVET, CTD","BONGO,CALVET,CTD")) %>%
mutate(Bongo_hrs = ifelse(Gear.Sampled == "BONGO", 0.33,0)) %>% # BONGO at all stations
mutate(BON_CTD_hrs = ifelse(Gear.Sampled == "BONGO,CTD",0.83,0)) %>%
mutate(BON_CalVET_hrs = ifelse(Gear.Sampled == "BONGO,CALVET", 0.66,0)) %>%
mutate(BON_Cal_CTD_hrs = ifelse(Gear.Sampled == "BONGO,CALVET,CTD",1.16,0)) %>%
#<<<<<<< Updated upstream
mutate(Station_Time = lubridate::dhours(rowSums(across(c(Bongo_hrs,BON_CTD_hrs,BON_CalVET_hrs,BON_Cal_CTD_hrs))))) %>% mutate(Ship_Speed = 11) %>% # Ship speed is Variable
mutate(lat_rad = LAT*pi/180) %>% mutate(long_rad = LON*pi/180) %>%
mutate(long_dif = long_rad - shift(long_rad)) %>%
#>>>>>>> Stashed changes
mutate(Dist_NM = ifelse(Station == 0,0,0) ) %>%
mutate(Dist_NM = distGeo(cbind(LON,LAT),cbind(shift(LON),shift(LAT)))/(1000*1.852)) %>% # distGEO does what code below does in base
#  mutate(Dist_NM = acos((sin(lag(lat_rad))*sin(lat_rad))+(cos(lag(lat_rad))*cos(lat_rad)*cos(long_dif)))/(pi/180)*60) %>%
mutate(Steam_T = Dist_NM/Ship_Speed) %>%
mutate(Steam_T = lubridate::dhours(Steam_T))
# 2. rearrange data to calculate time to travel to and complete station operations
shipslog <- SRTdata %>% select(Station, Grid.ID,Station_Time, Steam_T, Stn_Order) %>% # SRTdata will be replaced by filtered stations above
unite("Station",Station:Grid.ID, sep = "_", remove = FALSE) %>%
select(Station,Steam_T,Station_Time,Stn_Order) %>%
gather(key="Ops", Time_Dur, -Station,-Stn_Order) %>% arrange(Station) %>%
separate(Station, c("Station","Grid.ID"), sep = "_") %>%
transform(Station = as.numeric(Station)) %>% arrange(Stn_Order)
shipslog <- na.omit(shipslog)
# 3. Choose Departure Date
depart <- ymd_hm("2023-05-14 12:00")
# 4. Create a table of Station Completion Times
ShipsLog <- shipslog %>% group_by(Stn_Order, Station, Grid.ID) %>%
reframe(Time_Dur = lubridate::dseconds(sum(Time_Dur)))  %>%
mutate(Sta_Time =  depart) %>% mutate(cTime_Dur = cumsum(Time_Dur)) %>%
mutate(Sta_Time = cTime_Dur + Sta_Time) %>% select(Station, Stn_Order, Grid.ID,Sta_Time)
# 5. Plot filtered station map with survey track
StaMapF <-ggplot()+geom_contour(data = bf, aes(x=x, y=y, z=z),breaks=c(-50),linewidth=c(0.5),colour="light grey")+ # add 50m contour
geom_contour(data = bf, aes(x=x, y=y, z=z), breaks=c(-100), linewidth=c(0.5), colour="darkgrey")+ # add 100m contour
geom_contour(data = bf, aes(x=x, y=y, z=z),breaks=c(-200),linewidth=c(0.3), colour="black")+ # add 200m contour
geom_sf(data = world)+coord_sf(xlim = lons, ylim = lats, expand = FALSE)+ # add coastline
#Plot points & station track
geom_point(data = SRTdata, mapping = aes(LON, LAT, shape = Gear.Sampled), size = 1)+
geom_path(data = SRTdata, mapping = aes(LON, LAT), linewidth = 0.25) +
geom_text(data = SRTdata, mapping = aes(LON, LAT, label = Station ), nudge_y = -0.08, size = 2.5)+
scale_shape_discrete()+ theme_bw()+xlab("Longitude")+ylab("Latitude")+ ggtitle(paste(ScenName,length(Scenario),"Stns")) +
theme(axis.text.x=element_text(size=10, color = "black"), axis.text.y = element_text(size=10, color = "black"))
#StaMapF
#ggsave(paste0(ScenName,".png"),path = here("Docs"), height = 8.5, width = 11, units = "in")
View(Sta)
toupper(Sta$Grid.ID)
View(GridMeanZ)
GridStaData <- read.csv(here("Data","2023-10-18 WGOA Grid Sta Depth Data.csv"))
GridMeanZ <- GridStaData %>% group_by(FOCI_GRID) %>% summarise(MeanZ = mean(BOTTOM_DEPTH)) %>%
dplyr::rename("Grid.ID"="FOCI_GRID")
View(GridMeanZ)
Sta <- Sta %>% left_join(.,GridMeanZ, by = "Grid.ID")
View(Sta)
View(GridMeanZ)
Sta <- WGOAdata %>% left_join(.,FinalSta) %>%
filter(Station %in% FinalSta$Station) %>%
arrange(Stn_Order) %>% toupper(Grid.ID)
View(Sta)
toupper(Sta$Grid.ID)
Sta <- Sta %>% left_join(.,GridMeanZ, by = "Grid.ID")
View(Sta)
Sta <- WGOAdata %>% left_join(.,FinalSta) %>%
filter(Station %in% FinalSta$Station) %>%
arrange(Stn_Order)
toupper(Sta$Grid.ID)
View(Sta)
toupper(Sta$Grid.ID)
Sta <- WGOAdata %>% left_join(.,FinalSta) %>%
filter(Station %in% FinalSta$Station) %>%
arrange(Stn_Order)
Sta <- WGOAdata %>% left_join(.,FinalSta) %>%
filter(Station %in% FinalSta$Station) %>%
arrange(Stn_Order) %>% toupper(Grid.ID)
Sta <- WGOAdata %>% left_join(.,FinalSta) %>%
filter(Station %in% FinalSta$Station) %>%
arrange(Stn_Order) %>% mutate(Grid.ID = toupper(Grid.ID))
View(Sta)
Sta <- Sta %>% left_join(.,GridMeanZ, by = "Grid.ID")
View(Sta)
